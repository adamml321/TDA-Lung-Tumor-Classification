{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify 3-D Lung Tumor Scans Based on Persistence Images\n",
    "\n",
    "This will test a range of persistence imager parameters to find the best representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import math\n",
    "import os\n",
    "import gudhi as gd\n",
    "import pandas as pd\n",
    "import PersistenceImages.persistence_images as pimg\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import  Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imaging Data\n",
    "rad_phom_0s = np.load('C:/Users/Adam/Documents/Datasets/Radiomics_Homology/rad_phom_0s.npy', allow_pickle = True)\n",
    "rad_phom_1s = np.load('C:/Users/Adam/Documents/Datasets/Radiomics_Homology/rad_phom_1s.npy', allow_pickle = True)\n",
    "rad_phom_2s = np.load('C:/Users/Adam/Documents/Datasets/Radiomics_Homology/rad_phom_2s.npy', allow_pickle = True)\n",
    "\n",
    "radg_phom_0s = np.load('C:/Users/Adam/Documents/Datasets/Radiogenomics_Homology/radg_phom_0s.npy', allow_pickle = True)\n",
    "radg_phom_1s = np.load('C:/Users/Adam/Documents/Datasets/Radiogenomics_Homology/radg_phom_1s.npy', allow_pickle = True)\n",
    "radg_phom_2s = np.load('C:/Users/Adam/Documents/Datasets/Radiogenomics_Homology/radg_phom_1s.npy', allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clinical Data\n",
    "#Radiomics clinical data\n",
    "rad_clinical = pd.read_csv(\"rad_clinic.csv\")\n",
    "rad_clinical = rad_clinical.drop(rad_clinical.index[127]) #Tumor 128 has no segmentation\n",
    "\n",
    "rad_histology = rad_clinical.Histology\n",
    "\n",
    "#Radiogenomics clinical data\n",
    "radg_clinical = pd.read_csv(\"radg_clinic.csv\", skiprows = range(1,50))\n",
    "radg_clinical = radg_clinical[0:146]\n",
    "radg_clinical = radg_clinical.drop(radg_clinical.index[[8, 142]]) #9 and 143 have no segmentation\n",
    "\n",
    "radg_clinical[\"Histology\"] = radg_clinical['Histology'].str.lower()\n",
    "radg_histology = radg_clinical.Histology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adam\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "C:\\Users\\Adam\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "C:\\Users\\Adam\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "#Combine Datasets\n",
    "\n",
    "#Identify indices we want to keep\n",
    "rad_adeno = rad_histology == 'adenocarcinoma'\n",
    "rad_squamous = rad_histology == 'squamous cell carcinoma'\n",
    "radg_adeno = radg_histology == 'adenocarcinoma'\n",
    "radg_squamous = radg_histology == 'squamous cell carcinoma'\n",
    "\n",
    "#Select clinical data\n",
    "rad_histology_adsq = np.array(rad_histology[rad_adeno | rad_squamous])\n",
    "radg_histology_adsq = np.array(radg_histology[radg_adeno | radg_squamous])\n",
    "\n",
    "#Select persistent homology data\n",
    "rad_phom_0s_adsq = rad_phom_0s[rad_adeno | rad_squamous]\n",
    "rad_phom_1s_adsq = rad_phom_1s[rad_adeno | rad_squamous]\n",
    "rad_phom_2s_adsq = rad_phom_2s[rad_adeno | rad_squamous]\n",
    "\n",
    "radg_phom_0s_adsq = radg_phom_0s[radg_adeno | radg_squamous]\n",
    "radg_phom_1s_adsq = radg_phom_1s[radg_adeno | radg_squamous]\n",
    "radg_phom_2s_adsq = radg_phom_2s[radg_adeno | radg_squamous]\n",
    "\n",
    "\n",
    "histology_adsq = np.array(list(radg_histology_adsq) + list(rad_histology_adsq))\n",
    "phom_0s_adsq = np.array(list(radg_phom_0s_adsq) + list(rad_phom_0s_adsq))\n",
    "phom_1s_adsq = np.array(list(radg_phom_1s_adsq) + list(rad_phom_1s_adsq))\n",
    "phom_2s_adsq = np.array(list(radg_phom_2s_adsq) + list(rad_phom_2s_adsq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions to streamline parameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateImager(pixel_size, sigma):\n",
    "    pers_imager = pimg.PersistenceImager()\n",
    "    pers_imager.pixel_size = pixel_size\n",
    "    pers_imager.birth_range = (0,1)\n",
    "    pers_imager.pers_range = (0,1)\n",
    "    pers_imager.kernel_params['sigma'][0] = [sigma, 0]\n",
    "    pers_imager.kernel_params['sigma'][1] = [0, sigma]\n",
    "    return(pers_imager)\n",
    "    \n",
    "    \n",
    "def HomologyToImageVector(phom_0, phom_1, phom_2, imager):\n",
    "    \n",
    "    pers_img_0 = imager.transform(phom_0, skew=True)\n",
    "    pers_img_1 = imager.transform(phom_1, skew=True)\n",
    "    pers_img_2 = imager.transform(phom_2, skew=True)\n",
    "    \n",
    "    pers_img_0 = np.resize(pers_img_0, (1, len(pers_img_0)**2))\n",
    "    pers_img_1 = np.resize(pers_img_1, (1, len(pers_img_1)**2))\n",
    "    if len(phom_2) == 0: #Lung 192 is why we can't have nice things\n",
    "        pers_img_2 = np.zeros_like(pers_img_1)\n",
    "    else:\n",
    "        pers_img_2 = imager.transform(phom_2, skew=True)\n",
    "        \n",
    "    return(pers_img_0, pers_img_1, pers_img_2)\n",
    "\n",
    "\n",
    "def AllPhomsToImages(phom_0s, phom_1s, phom_2s, imager):\n",
    "    concatenated_images = []\n",
    "    for i in range(len(phom_0s)):\n",
    "        \n",
    "        pimg_0, pimg_1, pimg_2 = HomologyToImageVector(phom_0s[i], phom_1s[i], phom_2s[i], imager)\n",
    "        imgs = np.concatenate((pimg_0[0], pimg_1[0], pimg_2[0]), axis=0)\n",
    "        concatenated_images.append(imgs)\n",
    "        \n",
    "    concatenated_images = np.array(concatenated_images)\n",
    "    return(concatenated_images)\n",
    "\n",
    "def ClassifyImages_Logreg(images, histology):\n",
    "    #First we need to shuffle this dataset since otherwise k-fold will magnify batch effects.\n",
    "    images, histology = shuffle(images, histology, random_state = 10)\n",
    "\n",
    "    scores = []\n",
    "    y_pred = []\n",
    "\n",
    "    clf_logreg = LogisticRegression(penalty = 'l1', solver='liblinear')\n",
    "    cv = KFold(n_splits=5, shuffle=False)\n",
    "    \n",
    "    for train_index, test_index in cv.split(images):\n",
    "\n",
    "        X_train, X_test = images[train_index], images[test_index]\n",
    "        y_train, y_test = histology[train_index], histology[test_index]\n",
    "        clf_logreg.fit(X_train, y_train)\n",
    "        y_pred.append(list(clf_logreg.predict(X_test)))\n",
    "        scores.append(clf_logreg.score(X_test, y_test))\n",
    "    \n",
    "    return(np.mean(scores))\n",
    "\n",
    "def ClassifyImages_XGb(images, histology):\n",
    "    #First we need to shuffle this dataset since otherwise k-fold will magnify batch effects.\n",
    "    images, histology = shuffle(images, histology, random_state = 10)\n",
    "\n",
    "    scores = []\n",
    "    y_pred = []\n",
    "    \n",
    "    clf_xgboost = XGBClassifier()\n",
    "    cv = KFold(n_splits=5, shuffle=False)\n",
    "    \n",
    "    for train_index, test_index in cv.split(images):\n",
    "\n",
    "        X_train, X_test = images[train_index], images[test_index]\n",
    "        y_train, y_test = histology[train_index], histology[test_index]\n",
    "        clf_xgboost.fit(X_train, y_train)\n",
    "        y_pred.append(list(clf_xgboost.predict(X_test)))\n",
    "        scores.append(clf_xgboost.score(X_test, y_test))\n",
    "    \n",
    "    return(np.mean(scores))\n",
    "\n",
    "def ParameterSearchInstance_Logreg(pixel_size, sigma, phom_0s, phom_1s, phom_2s, histology):\n",
    "    imager = CreateImager(pixel_size, sigma)\n",
    "    images = AllPhomsToImages(phom_0s, phom_1s, phom_2s, imager)\n",
    "    acc = ClassifyImages_Logreg(images, histology)\n",
    "    return(acc)\n",
    "\n",
    "def ParameterSearchInstance_XGb(pixel_size, sigma, phom_0s, phom_1s, phom_2s, histology):\n",
    "    imager = CreateImager(pixel_size, sigma)\n",
    "    images = AllPhomsToImages(phom_0s, phom_1s, phom_2s, imager)\n",
    "    acc = ClassifyImages_XGb(images, histology)\n",
    "    return(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7123188405797102\n",
      "Wall time: 21min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "acc = ParameterSearchInstance_XGb(0.01, 0.001, phom_0s_adsq, phom_1s_adsq, phom_2s_adsq, histology_adsq)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adam\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Adam\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Adam\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Adam\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Adam\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Adam\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Adam\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Adam\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Adam\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Adam\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Adam\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Adam\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Adam\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Adam\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Adam\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Adam\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Adam\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Adam\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14h 14min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#pixel_sizes = [0.01, 0.05, 0.1, 0.2, 0.5]\n",
    "#sigmas = [0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "\n",
    "pixel_sizes = [0.005, 0.01, 0.05, 0.1, 0.2]\n",
    "sigmas = [0.0005, 0.001, 0.005, 0.01, 0.05]\n",
    "\n",
    "accs_Logreg = np.zeros((len(pixel_sizes), len(sigmas)))\n",
    "accs_XGb = np.zeros((len(pixel_sizes), len(sigmas)))\n",
    "\n",
    "for i in range(len(pixel_sizes)):\n",
    "    for j in range(len(sigmas)):\n",
    "        accs_Logreg[i,j] = ParameterSearchInstance_Logreg(pixel_sizes[i], sigmas[j], phom_0s_adsq, phom_1s_adsq, phom_2s_adsq, histology_adsq)\n",
    "        accs_XGb[i,j] = ParameterSearchInstance_XGb(pixel_sizes[i], sigmas[j], phom_0s_adsq, phom_1s_adsq, phom_2s_adsq, histology_adsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.64565217 0.63103154 0.60485934 0.5756607  0.52612958]\n",
      " [0.66892583 0.66031543 0.68917306 0.6544757  0.5756607 ]\n",
      " [0.70080989 0.69786871 0.70959079 0.69505541 0.73554987]\n",
      " [0.69219949 0.70085251 0.70085251 0.70375107 0.69791134]\n",
      " [0.69791134 0.70375107 0.70366581 0.69202899 0.68921569]]\n",
      "[[0.72693947 0.70946292 0.671526   0.6745098  0.69769821]\n",
      " [0.68026428 0.71231884 0.6773231  0.70643649 0.66577153]\n",
      " [0.68913043 0.70643649 0.68904518 0.63661552 0.65690537]\n",
      " [0.65140665 0.69185848 0.65690537 0.62800512 0.63665814]\n",
      " [0.67728048 0.6541347  0.68921569 0.6455243  0.66287298]]\n"
     ]
    }
   ],
   "source": [
    "print(accs_Logreg)\n",
    "print(accs_XGb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
