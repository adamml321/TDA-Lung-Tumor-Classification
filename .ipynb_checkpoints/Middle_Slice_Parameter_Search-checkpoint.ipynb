{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify 2-D Lung Tumor Middle Slices Based on Persistence Images\n",
    "This will pick up where '2D_complex_generator.ipynb' left off by representing persistent homology with persistence images (with a range of parameters) and running machine learning classifiers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import math\n",
    "import os\n",
    "import gudhi as gd\n",
    "import pandas as pd\n",
    "import PersistenceImages.persistence_images as pimg\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Data and Combine Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imaging Data\n",
    "rad_phom_0s = np.load('./Radiomics_Homology/rad_phom_middle_0s.npy', allow_pickle = True)\n",
    "rad_phom_1s = np.load('./Radiomics_Homology/rad_phom_middle_1s.npy', allow_pickle = True)\n",
    "\n",
    "radg_phom_0s = np.load('./Radiogenomics_Homology/radg_phom_middle_0s.npy', allow_pickle = True)\n",
    "radg_phom_1s = np.load('./Radiogenomics_Homology/radg_phom_middle_1s.npy', allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clinical Data\n",
    "#Radiomics clinical data\n",
    "rad_clinical = pd.read_csv(\"rad_clinic.csv\")\n",
    "rad_clinical = rad_clinical.drop(rad_clinical.index[127]) #Tumor 128 has no segmentation\n",
    "\n",
    "rad_histology = rad_clinical.Histology\n",
    "\n",
    "#Radiogenomics clinical data\n",
    "radg_clinical = pd.read_csv(\"radg_clinic.csv\", skiprows = range(1,50))\n",
    "radg_clinical = radg_clinical[0:146]\n",
    "radg_clinical = radg_clinical.drop(radg_clinical.index[[8, 142]]) #9 and 143 have no segmentation\n",
    "\n",
    "radg_clinical[\"Histology\"] = radg_clinical['Histology'].str.lower()\n",
    "radg_histology = radg_clinical.Histology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine Datasets\n",
    "\n",
    "#Identify indices we want to keep\n",
    "rad_adeno = rad_histology == 'adenocarcinoma'\n",
    "rad_squamous = rad_histology == 'squamous cell carcinoma'\n",
    "radg_adeno = radg_histology == 'adenocarcinoma'\n",
    "radg_squamous = radg_histology == 'squamous cell carcinoma'\n",
    "\n",
    "#Select clinical data\n",
    "rad_histology_adsq = np.array(rad_histology[rad_adeno | rad_squamous])\n",
    "radg_histology_adsq = np.array(radg_histology[radg_adeno | radg_squamous])\n",
    "\n",
    "#Select persistent homology data\n",
    "rad_phom_0s_adsq = rad_phom_0s[rad_adeno | rad_squamous]\n",
    "rad_phom_1s_adsq = rad_phom_1s[rad_adeno | rad_squamous]\n",
    "\n",
    "radg_phom_0s_adsq = radg_phom_0s[radg_adeno | radg_squamous]\n",
    "radg_phom_1s_adsq = radg_phom_1s[radg_adeno | radg_squamous]\n",
    "\n",
    "\n",
    "histology_adsq = np.array(list(radg_histology_adsq) + list(rad_histology_adsq))\n",
    "phom_0s_adsq = np.array(list(rad_phom_0s_adsq) + list(radg_phom_0s_adsq))\n",
    "phom_1s_adsq = np.array(list(rad_phom_1s_adsq) + list(radg_phom_1s_adsq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions to Streamline Parameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateImager(pixel_size, sigma):\n",
    "    pers_imager = pimg.PersistenceImager()\n",
    "    pers_imager.pixel_size = pixel_size\n",
    "    pers_imager.birth_range = (0,1)\n",
    "    pers_imager.pers_range = (0,1)\n",
    "    pers_imager.kernel_params['sigma'][0] = [sigma, 0]\n",
    "    pers_imager.kernel_params['sigma'][1] = [0, sigma]\n",
    "    return(pers_imager)\n",
    "    \n",
    "    \n",
    "def HomologyToImageVector(phom_0, phom_1, imager):\n",
    "    \n",
    "    pers_img_0 = imager.transform(phom_0, skew=True)\n",
    "    pers_img_1 = imager.transform(phom_1, skew=True)\n",
    "    \n",
    "    pers_img_0 = np.resize(pers_img_0, (1, len(pers_img_0)**2))\n",
    "    pers_img_1 = np.resize(pers_img_1, (1, len(pers_img_1)**2))\n",
    "        \n",
    "    return(pers_img_0, pers_img_1)\n",
    "\n",
    "\n",
    "def AllPhomsToImages(phom_0s, phom_1s, imager):\n",
    "    concatenated_images = []\n",
    "    for i in range(len(phom_0s)):\n",
    "        \n",
    "        pimg_0, pimg_1 = HomologyToImageVector(phom_0s[i], phom_1s[i], imager)\n",
    "        imgs = np.concatenate((pimg_0[0], pimg_1[0]), axis=0)\n",
    "        concatenated_images.append(imgs)\n",
    "        \n",
    "    concatenated_images = np.array(concatenated_images)\n",
    "    return(concatenated_images)\n",
    "\n",
    "def ClassifyImages(images, histology):\n",
    "    #First we need to shuffle this dataset since otherwise k-fold will magnify batch effects.\n",
    "    images, histology = shuffle(images, histology, random_state = 10)\n",
    "\n",
    "    scores = []\n",
    "    y_pred = []\n",
    "\n",
    "    clf_logreg = LogisticRegression(penalty = 'l1', solver='liblinear')\n",
    "\n",
    "    cv = KFold(n_splits=5, shuffle=False)\n",
    "    for train_index, test_index in cv.split(images):\n",
    "\n",
    "        X_train, X_test = images[train_index], images[test_index]\n",
    "        y_train, y_test = histology[train_index], histology[test_index]\n",
    "        clf_logreg.fit(X_train, y_train)\n",
    "        y_pred.append(list(clf_logreg.predict(X_test)))\n",
    "        scores.append(clf_logreg.score(X_test, y_test))\n",
    "    \n",
    "    return(np.mean(scores))\n",
    "\n",
    "def ParameterSearchInstance(pixel_size, sigma, phom_0s, phom_1s, histology):\n",
    "    imager = CreateImager(pixel_size, sigma)\n",
    "    images = AllPhomsToImages(phom_0s, phom_1s, imager)\n",
    "    acc = ClassifyImages(images, histology)\n",
    "    return(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do Grid Search of Persistence Imager Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.569693094629156\n"
     ]
    }
   ],
   "source": [
    "acc = ParameterSearchInstance(0.05, 0.005, phom_0s_adsq, phom_1s_adsq, histology_adsq)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_sizes = [0.05, 0.1, 0.2, 0.5]\n",
    "sigmas = [0.01, 0.005, 0.01, 0.05, 0.1]\n",
    "accs = np.zeros((len(pixel_sizes), len(sigmas)))\n",
    "\n",
    "for i in range(len(pixel_sizes)):\n",
    "    for j in range(len(sigmas)):\n",
    "        accs[i,j] = ParameterSearchInstance(pixel_sizes[i], sigmas[j], phom_0s_adsq, phom_1s_adsq, histology_adsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.58132992 0.56679454 0.58132992 0.52612958 0.52612958]\n",
      " [0.56683717 0.62212276 0.56683717 0.5842711  0.54931799]\n",
      " [0.5842711  0.59011083 0.5842711  0.59296675 0.61040068]\n",
      " [0.59296675 0.58716965 0.59296675 0.59300938 0.59590793]]\n",
      "\n",
      "0.5813299232736572 0.5667945439045183 0.5813299232736572 0.5261295822676897 0.5261295822676897\n",
      "\n",
      "0.5668371696504689 0.6221227621483376 0.5668371696504689 0.5842710997442454 0.5493179880647912\n",
      "\n",
      "0.5842710997442456 0.5901108269394715 0.5842710997442456 0.5929667519181585 0.6104006820119353\n",
      "\n",
      "0.5929667519181585 0.5871696504688831 0.5929667519181585 0.5930093776641091 0.5959079283887468\n"
     ]
    }
   ],
   "source": [
    "print(accs)\n",
    "for line in accs:\n",
    "    print()\n",
    "    print(*line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
